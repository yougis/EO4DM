<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mathis Nehauser">
<meta name="author" content="Hugo Roussaffa">
<meta name="keywords" content="Sécheresse végétale, Pacifique Sud, Observation de la Terre">

<title>Suivi de la sécheresse dans les territoires insulaire du Pacifique</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="manuel-exploitation_files/libs/clipboard/clipboard.min.js"></script>
<script src="manuel-exploitation_files/libs/quarto-html/quarto.js"></script>
<script src="manuel-exploitation_files/libs/quarto-html/popper.min.js"></script>
<script src="manuel-exploitation_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="manuel-exploitation_files/libs/quarto-html/anchor.min.js"></script>
<link href="manuel-exploitation_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="manuel-exploitation_files/libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="manuel-exploitation_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="manuel-exploitation_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="manuel-exploitation_files/libs/bootstrap/bootstrap-def314685997ae775ed87effcd90cd1a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table des matières</h2>
   
  <ul>
  <li><a href="#présentation-générale" id="toc-présentation-générale" class="nav-link active" data-scroll-target="#présentation-générale"><span class="header-section-number">1</span> Présentation générale</a></li>
  <li><a href="#configuration-google-earth-engine-gee" id="toc-configuration-google-earth-engine-gee" class="nav-link" data-scroll-target="#configuration-google-earth-engine-gee"><span class="header-section-number">2</span> Configuration Google Earth Engine (GEE)</a></li>
  <li><a href="#utilisation-test" id="toc-utilisation-test" class="nav-link" data-scroll-target="#utilisation-test"><span class="header-section-number">3</span> Utilisation “Test”</a>
  <ul class="collapse">
  <li><a href="#fichier-de-configuration" id="toc-fichier-de-configuration" class="nav-link" data-scroll-target="#fichier-de-configuration"><span class="header-section-number">3.1</span> Fichier de configuration</a></li>
  <li><a href="#installer-via-pip" id="toc-installer-via-pip" class="nav-link" data-scroll-target="#installer-via-pip"><span class="header-section-number">3.2</span> Installer via pip</a></li>
  <li><a href="#installer-via-conda" id="toc-installer-via-conda" class="nav-link" data-scroll-target="#installer-via-conda"><span class="header-section-number">3.3</span> Installer via conda</a></li>
  <li><a href="#exécution" id="toc-exécution" class="nav-link" data-scroll-target="#exécution"><span class="header-section-number">3.4</span> Exécution</a></li>
  </ul></li>
  <li><a href="#utilisation-service-régulier" id="toc-utilisation-service-régulier" class="nav-link" data-scroll-target="#utilisation-service-régulier"><span class="header-section-number">4</span> Utilisation “Service-Régulier”</a>
  <ul class="collapse">
  <li><a href="#fonctionement-docker" id="toc-fonctionement-docker" class="nav-link" data-scroll-target="#fonctionement-docker"><span class="header-section-number">4.1</span> Fonctionement Docker</a></li>
  <li><a href="#exécution-docker" id="toc-exécution-docker" class="nav-link" data-scroll-target="#exécution-docker"><span class="header-section-number">4.2</span> Exécution Docker</a></li>
  </ul></li>
  <li><a href="#algorithmes" id="toc-algorithmes" class="nav-link" data-scroll-target="#algorithmes"><span class="header-section-number">5</span> Algorithmes</a></li>
  <li><a href="#cas-dusages" id="toc-cas-dusages" class="nav-link" data-scroll-target="#cas-dusages"><span class="header-section-number">6</span> Cas d’usages</a>
  <ul class="collapse">
  <li><a href="#préparation-du-dossier-annex" id="toc-préparation-du-dossier-annex" class="nav-link" data-scroll-target="#préparation-du-dossier-annex"><span class="header-section-number">6.1</span> Préparation du dossier ANNEX</a></li>
  <li><a href="#préconisations-de-configuration-pour-un-premier-test-de-lancement-mode-manuel" id="toc-préconisations-de-configuration-pour-un-premier-test-de-lancement-mode-manuel" class="nav-link" data-scroll-target="#préconisations-de-configuration-pour-un-premier-test-de-lancement-mode-manuel"><span class="header-section-number">6.2</span> Préconisations de configuration pour un premier test de lancement (MODE = MANUEL)</a></li>
  </ul></li>
  <li><a href="#intégration-continue-ci" id="toc-intégration-continue-ci" class="nav-link" data-scroll-target="#intégration-continue-ci"><span class="header-section-number">7</span> Intégration Continue (CI)</a>
  <ul class="collapse">
  <li><a href="#agent-azure-devops" id="toc-agent-azure-devops" class="nav-link" data-scroll-target="#agent-azure-devops"><span class="header-section-number">7.1</span> Agent Azure DevOps</a></li>
  <li><a href="#déclenchement" id="toc-déclenchement" class="nav-link" data-scroll-target="#déclenchement"><span class="header-section-number">7.2</span> Déclenchement</a></li>
  <li><a href="#déploiement-en-prod" id="toc-déploiement-en-prod" class="nav-link" data-scroll-target="#déploiement-en-prod"><span class="header-section-number">7.3</span> Déploiement en PROD</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Autres formats</h2><ul><li><a href="manuel-exploitation.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Suivi de la sécheresse dans les territoires insulaire du Pacifique</h1>
<p class="subtitle lead">Document d’exploitation technique</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Auteur·rice·s</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Mathis Nehauser </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Insight
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Hugo Roussaffa </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            OEIL - Observatoire de l’Environnement en Nouvelle-Calédonie
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Date de publication</div>
    <div class="quarto-title-meta-contents">
      <p class="date">24-03-2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Résumé</div>
    Ce document expliaue comment exploiter la pipeline de traitement permettant la production des indicateurs de sécheresse développés dans le cadre du projet EO4DM (Earth Observation For Drought Monitoring) ainsi que des differentes évolutions effectués dans le cadre du partenaria avec l’Observaoite de l’environnement en Nouvelle Calédonie.
  </div>
</div>

<div>
  <div class="keywords">
    <div class="block-title">Mots clés</div>
    <p>Sécheresse végétale, Pacifique Sud, Observation de la Terre</p>
  </div>
</div>

</header>


<section id="présentation-générale" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="présentation-générale"><span class="header-section-number">1</span> Présentation générale</h2>
<p>Ce dépôt contient la pipeline de traitement permettant la production des indicateurs de sécheresse développés dans le cadre du projet EO4DM (Earth Observation For Drought Monitoring). A la racine, se trouvent les fichiers servant à l’installation, l’intégration continue ainsi que la configuration de lancement de la pipeline.</p>
<p>Le dossier “<a href="dmpipeline">dmpipeline</a>” contient les différents packages et scripts en python pour le traitement des produits intervenant dans la pipeline (images satellites, données météorologiques). On y trouve les scripts principaux des trois chaines LOCALE, GLOBALE et ALERTE : - <a href="dmpipeline/LocalDrought_ProcessingChain.py">LocalDrought_ProcessingChain.py</a> : sécheresse végétale à haute résolution spatiale (10 m) - <a href="dmpipeline/GlobalDrought_ProcessingChain.py">GlobalDrought_ProcessingChain.py</a> : sécheresse végétale à moyenne résolution spatiale (500 m) - <a href="dmpipeline/AlertDrought_ProcessingChain.py">AlertDrought_ProcessingChain.py</a> : alertes sécheresse à échelle régionale (synthèse par zones)</p>
<p>Quatre sous-dossiers correspondent aux modules (packages) suivants : - <a href="dmpipeline/ALERT_Processing">ALERT_Processing</a> : scripts de la chaine Alerte et identifiants pour l’accès aux produits Copernicus (<a href="dmpipeline/ALERT_Processing/ftp_accounts">ftp_accounts</a>) - <a href="dmpipeline/DROUGHT_Processing">DROUGHT_Processing</a> : scripts pour le calcul des indicateurs sécheresse aux échelles locales et globales - <a href="dmpipeline/GEE_Processing">GEE_Processing</a> : scripts pour l’accès, le prétraitement et le téléchargement des produits GEE (Google Earth Engine), ainsi que les identifiants Google (<a href="dmpipeline/GEE_Processing/gee_accounts">gee_accounts</a>) - <a href="dmpipeline/GEOSTATS_Processing">GEOSTATS_Processing</a> : scripts pour le calcul de statistiques spatiales des indicateurs</p>
<p>Le sous-dossier <a href="dmpipeline/tests_notebooks">tests_notebooks</a> contient des notebooks jupyter pour le test de certaines fonctionnalités des chaines. Certains tests unitaires restent à faire.</p>
<p>Le sous-dossier <a href="dmpipeline/ANNEX_Data">ANNEX_Data</a> contient des données annexes pouvant être nécessaires à la pipeline : - Landsat_Grid_World : contours des différentes tuiles landsat sur l’ensemble du globe, nécessairement utilisées par la chaine LOCALE - Territory : exemple de données pouvant être utilisées par la chaine GLOBALE pour le calcul de statistiques spatiales (/Areas, /Landcover), et nécessairement utilisées par la chaine ALERTE (/Stations) . Ici, à titre d’exemple, les produits fournis sont ceux de la Nouvelle-Calédonie et devront être adaptés/modifiés pour d’autres territoires d’étude.</p>
<p>Un sous-dossier <a href="dmpipeline/DOC">DOC</a> contient de la documentation utile.</p>
<p>La pipeline peut s’utiliser de deux manières : - Utilisation “Test”, pour un production en un seul coup, chaine par chaine, et qui est recommandée pour une première prise en main des chaines (cf.&nbsp;section <a href="#utilisation-%22test%22">Utilisation “Test”</a>) - Utilisation “Service-Régulier, pour une production continue et parallelisée des chaines via un environnenent Docker, adaptée à la mise en place d’un service de production régulier (cf.&nbsp;section <a href="#utilisation-%22service-régulier%22">Utilisation “Service-Régulier”</a>)</p>
</section>
<section id="configuration-google-earth-engine-gee" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="configuration-google-earth-engine-gee"><span class="header-section-number">2</span> Configuration Google Earth Engine (GEE)</h2>
<p>Pour collecter et prétraiter les produits satellites MODIS, LANDSAT-7-8-9 et SENTINEL-2, les chaines LOCALES et GLOBALES se basent sur l’API python GEE (earthengine-api).</p>
<p>Afin que la pipeline appelle correctement l’API, l’utilisateur doit au préalable : 1) S’enregistrer sur GEE et créer un projet dédié à l’utilisation de la pipeline (cf.&nbsp;<a href="https://code.earthengine.google.com/register">Register</a>) 2) Créer un compte de service Google dédié qui permettra l’authentification/initialisation automatique de l’API GEE à chaque lancement de la pipeline (cf.&nbsp;<a href="https://developers.google.com/earth-engine/guides/service_account">Service Acccount</a>) 3) Générer une clé privée au format JSON contenant les identifiants du compte 4) Placer la clé privée dans le dossier <a href="dmpipeline/GEE_Processing/gee_accounts">gee_accounts</a></p>
<p>Depuis l’espace en ligne du projet GEE (Asset Manager, Code Editor) : 1) Créer un nouveau dossier ‘Annex’ (cf.&nbsp;<a href="https://developers.google.com/earth-engine/guides/asset_manager">Managing Assets</a>) 2) Importer le fichier <a href="dmpipeline/ANNEX_Data/Landsat_Grid_World/Landsat_Grid_World.zip">Landsat_Grid_World.zip</a> dans ‘projects/id-du-projet-gee/assets’ (cf.&nbsp;<a href="https://developers.google.com/earth-engine/guides/table_upload">Importing Table Data</a>) 3) Déplacer le fichier Landsat_Grid_World dans ‘Annex’</p>
<p>Pour la chaine LOCALE, il est possible de définir une zone selon laquelle les indices GEE seront découpés (par défault la découpe est faite selon l’emprise des tuiles Landsat). Pour cela : 1) Générer une couche vecteur au format shapefile contenant la (les) contour(s) de la zone (plusieurs polygones sont possibles) 2) Compresser dans un fichier zip nommé ‘Landmask_Grid_ROI.zip’ 3) Depuis l’espace en ligne du projet GEE, importer le fichier Landmask_Grid_ROI dans ‘projects/id-du-projet-gee/assets’, puis le déplacer dans ‘Annex’</p>
</section>
<section id="utilisation-test" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="utilisation-test"><span class="header-section-number">3</span> Utilisation “Test”</h2>
<p>Le fichier <a href="setup.py">setup.py</a> installe les différents modules de la pipeline.</p>
<p>Les librairies python nécessaires sont : - rasterio - pandas - geopandas - gdal - earthengine-api - PyDrive - python-dotenv - setuptools - scipy - tqdm</p>
<section id="fichier-de-configuration" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="fichier-de-configuration"><span class="header-section-number">3.1</span> Fichier de configuration</h3>
<p>Le fichier <a href="Config_process.env">Config_process.env</a> configure le lancement des chaines. Plusieurs variables d’environnement sont à définir selon l’usage souhaité. Pour une utilisation via Docker, ne pas modifier ce fichier et se référer directement à la section <a href="#utilisation-service-régulier">Utilisation “Service-Régulier</a>.</p>
<p>Les différentes variables de configuration et leur fonction sont décrites dans le fichier, dont certaines sont facultatives. On y trouve tout d’abord les chemins vers les dossiers d’écriture (WRK_DIR) et de lecture (DATA_HISTO, ANNEX_DIR) des chaines, spécifiques à l’environnement d’installation de la pipeline. Ensuite, un certain nombre de variables de fonctionnement permettent de paramétrer les traitements à réaliser. Voici les principales variables à renseigner : - TERRITORY : nom anglais du Territoire/Pays à traiter, nécessaire dans GEE pour collecter les produits satellites - MODE : Mode de fonctionnement des chaines (AUTO, MANUAL, INDICES, DROUGHT) - PERIOD_START : Date de début de la période à traiter (inclusive) - PERIOD_END : Date de fin de la période à traiter (exclusive) - TILES_L : Nom des tuiles landsat à traiter (facultatif) - TILES_S2 : Nom des tuiles sentinel-2 à traiter (facultatif)</p>
</section>
<section id="installer-via-pip" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="installer-via-pip"><span class="header-section-number">3.2</span> Installer via pip</h3>
<p>Le fichier <a href="libraries.txt">libraries</a> décrit les dépendances nécessaires.</p>
<p>S’assurer d’avoir installé virtualenv, se placer à la racine (dossier EO4DM), et exécuter :</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> venv dmpipeline</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> dmpipeline/bin/activate <span class="er">(</span><span class="ex">linux</span><span class="kw">)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">./dmpipeline/Scripts/Activate.ps1</span> <span class="er">(</span><span class="ex">windows</span><span class="kw">)</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-r</span> libraries.txt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> setup.py install</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Installer <code>rasterio</code> avec pip peut être problématique, en particulier avec Windows (cf.&nbsp;<a href="https://iotespresso.com/installing-rasterio-in-windows/">link</a>). Si c’est le cas, privilégier conda.</p>
</section>
<section id="installer-via-conda" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="installer-via-conda"><span class="header-section-number">3.3</span> Installer via conda</h3>
<p>Le fichier <a href="environment.yml">environment.yml</a> décrit les dépendances nécessaires.</p>
<p>Exécuter :</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> env create <span class="at">--file</span> environment.yml</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate dmpipeline</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> setup.py install</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exécution" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="exécution"><span class="header-section-number">3.4</span> Exécution</h3>
<p>Une fois le fichier de configuration complété, chaque chaine se lance de manière indépendante. Ici, chaque chaine sera exécutée une seule fois sur la période et la région souhaitées. Une fois l’ensemble des indicateurs calculés, la chaine s’arrête et c’est à l’utilisateur de la relancer si nécessaire.</p>
<p>Exécuter la chaine locale :</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">localDM</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Exécuter la chaine globale :</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">globalDM</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Exécuter la chaine alerte :</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">alertDM</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="utilisation-service-régulier" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="utilisation-service-régulier"><span class="header-section-number">4</span> Utilisation “Service-Régulier”</h2>
<p>Il est possible de lancer et exécuter les différentes chaines via Docker. Chaque chaine aura ainsi son conteneur Docker associé, mais basée sur une image commune qui contiendra l’ensemble des librairies nécessaires au projet en utilisant un environnement Conda. Cette image est basée sur Linux, avec une installation de Python et Conda : - <a href="Dockerfile">Dockerfile</a> contient les instructions pour la construction de l’image Docker - <a href="docker-compose.yml">docker-compose.yml</a> définit les services des différents dockers (variables entrées/sorties, image docker utilisée)</p>
<section id="fonctionement-docker" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="fonctionement-docker"><span class="header-section-number">4.1</span> Fonctionement Docker</h3>
<p>Afin de pouvoir exécuter la pipeline selon différents modes, le dockerfile lance le fichier <a href="entrypoint.sh">entrypoint.sh</a>. Celui-ci prend en entrée la variable d’environnement MODE définie dans le dockercompose et permettant un lancement : - soit automatique et continue, qui fait appel au script python <a href="control_autorun.py">control_autorun.py</a> dans lequel une boucle while exécute la chaine de traitement en continue - soit en un seul coup (autres valeurs de MODE), équivalent à l’utilisation “Test” de la pipeline.</p>
<p>Tous les conteneurs sont regroupés dans le fichier <a href="docker-compose.yml">docker-compose.yml</a> où il est possible de paramétrer le script à exécuter via des variables d’environnement. Ces variables sont ensuite lues par le fichier de configuration <a href="Config_process.env">Config_process.env</a>. S’assurer donc de bien remplir le dockercompose avec les variables attendues en configuration. Toute variable non fournie dans le dockercompose sera considérée comme None dans le fichier de configuration, ce qui entrainera une erreur si les variables obligatoires ne sont pas définies.</p>
<p>La variable d’environnement WRK_DIR est par défaut reliée à la variable définie dans le fichier <a href="azure-pipelines.yml">azure-pipelines.yml</a> (cf.&nbsp;<a href="#intégration-continue-(ci)">Intégration Continue (CI)</a>). Dans le cas d’une utilisation sans CI de la pipeline, paramétrer directement le chemin du WRK_DIR dans le dockercompose (- WRK_DIR=chemin…).</p>
<p>Le fichier <a href="docker-compose.yml">docker-compose.yml</a> décrit à minima 3 dockers pour le lancement des 3 chaines principales. Néanmoins, il peut contenir autant de descriptions dockers que souhaitées, correspondant par exemple à différents cas d’usages : territoires, périodes, modes de lancements, etc. S’assurer de garder les mêmes paramètres d’entrées/sorties, en les mettant à jour selon l’usage souhaité (TERRITORY=…, MODE=…, PERIOD=…).</p>
<p>Les logs des scripts sont redirigés vers la sortie du conteneur pour les voir apparaître dans les logs via <code>docker logs &lt;container&gt; -f</code>. Pour cela, la sortie des scripts est redirigée vers le fichier <code>/proc/1/fd/1</code> qui est en fait la sortie du conteneur. L’instruction <code>2&gt;&amp;1</code> est également ajoutée pour que les erreurs soient retournées à la sortie du conteneur.</p>
</section>
<section id="exécution-docker" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="exécution-docker"><span class="header-section-number">4.2</span> Exécution Docker</h3>
<p>S’assurer au préalable d’avoir installé Docker sur sa machine.</p>
<p>Pour construire, créer/recréer les dockers et démarrer en mode détaché (arrière plan), exécuter :</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker-compose</span> up <span class="at">-d</span> <span class="at">--build</span> <span class="at">--force-recreate</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Pour stopper les dokers, exécuter :</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker-compose</span> down</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="algorithmes" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="algorithmes"><span class="header-section-number">5</span> Algorithmes</h2>
<p>Les différentes chaines de la pipeline, les étapes principales de traitements, ainsi que les produits d’entrée et de sortie, sont synthétisés dans le schéma <a href="dmpipeline/DOC/SCHEMA_GENERAL_EO4DM.png">SCHEMA_GENERAL_EO4DM.png</a> : <img src="dmpipeline/DOC/SCHEMA_GENERAL_EO4DM.png" class="img-fluid" alt="SCHEMA_GENERAL_EO4DM"></p>
<p>Le fichier <a href="dmpipeline/DOC/ALGO_CHAINES_EO4DM.png">ALGO_CHAINES_EO4DM.png</a> présente et décrit les algorithmes des chaines ALERTES, GLOBALES et LOCALES : <img src="dmpipeline/DOC/ALGO_CHAINES_EO4DM.png" class="img-fluid" alt="ALGO_CHAINES_EO4DM"></p>
</section>
<section id="cas-dusages" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="cas-dusages"><span class="header-section-number">6</span> Cas d’usages</h2>
<p>/!&nbsp;NE TRAITE POUR LE MOMENT QUE LES CHAINES GLOBALES/LOCALES</p>
<p>S’assurer d’avoir correctement configuré l’accès à l’API GEE <a href="#configuration-google-earth-engine-(gee)">Configuration Google Earth Engine (GEE)</a>.</p>
<section id="préparation-du-dossier-annex" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="préparation-du-dossier-annex"><span class="header-section-number">6.1</span> Préparation du dossier ANNEX</h3>
<p>Pour la chaine GLOBALE, s’il est prévu de fournir des statistiques spatiales par zones (DROUGHT_STATS=1) : - Créer le dossier ANNEX à l’endroit correspondant au chemin ANNEX_DIR donné dans le fichier de config - Y copier le dossier <a href="dmpipeline/ANNEX_Data/Territory">Territory</a> et son contenu - Renommer le dossier Territory selon le nom anglais du territoire à traiter, équivalent à la variable TERRITORY du fichier de configuration (en remplaçant les espaces et enventuels caractères spéciaux par des _) - Placer dans le dossier <a href="dmpipeline/ANNEX_Data/Territory/Areas">Areas</a> le shapefile contenant les contours des zones sur lesquelles seront calculées les statistiques - Il est possible (facultatif) de masquer certaines surfaces à partir d’un masque d’occupation du sol ESRI contenu dans le dossier <a href="dmpipeline/ANNEX_Data/Territory/Landcover">Landcover</a>. Cette phase demande encore des développements et ne fonctionne que pour la Nouvelle-Calédonie (fichier <a href="dmpipeline/ANNEX_Data/Territory/Landcover/58K_20200101-20210101.tif">.tif</a> fourni avec le code). Dans le cas où un autre territoire que la Nouvelle-Calédonie serait traité, veiller à supprimer le fichier .tif sinon une erreur surviendra au moment du calcul des statistiques.</p>
<p>Pour la chaine LOCALE, quelque soit la configuration de lancement : - Créer le dossier ANNEX (si pas déjà fait) à l’endroit correspondant au chemin ANNEX_DIR donné dans le fichier de config - Y copier le dossier <a href="dmpipeline/ANNEX_Data/Landsat_Grid_World">Landsat_Grid_World</a> - Dans le dossier Landsat_Grid_World, y décompresser le fichier zip</p>
<p>Le fichier de configuration <a href="Config_process.env">Config_process.env</a> est à compléter selon les préconisations ci-dessous.</p>
</section>
<section id="préconisations-de-configuration-pour-un-premier-test-de-lancement-mode-manuel" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="préconisations-de-configuration-pour-un-premier-test-de-lancement-mode-manuel"><span class="header-section-number">6.2</span> Préconisations de configuration pour un premier test de lancement (MODE = MANUEL)</h3>
<p>Pour un premier lancement des chaines sur un nouveau territoire, lancer celles-ci en mode manuel (MODE=MANUAL) sur une période d’un mois ou deux afin de vérifier la bonne exécution des différentes étapes de traitements ainsi que les produits fournis (indices, indicateurs). Pour la chaine LOCALE, idéalement se placer sur une période diposant à la fois de produits Landsat et S2 (2019 - ce jour)</p>
<p>Les variables d’environnement ASSET_EXPORT_* permettent de conserver sur GEE (Assets) les indices mono-date prétraités. Cela peut être utile pour : - Vérifier les indices mono-date en cas de production d’indices composites inattendus - Gagner du temps lors de la relance de la chaine sur une période déjà traitée. Si les indices mono-date sont déjà présents sur GEE et que ASSET_EXPORT_*=1, la chaine vient directement les lire, permettant un calcul plus rapide par la suite des indices composites.</p>
<p>Pour la chaine GLOBALE : - Définir la bounding box d’extraction des produits MODIS (lon_min, lat_min, lon_max, lat_max). A savoir que ce paramétrage est obligatoire lors du premier lancement, mais qu’il est ensuite facultatif pour de prochains lancements de la chaine sur la même zone (la chaine redécoupera ensuite les nouveaux indices selon l’emprise des produits historiques déjà calculés) - Si calcul des statistiques spatiales, mettre DROUGHT_STATS à 1, et paramétrer KEY_STAT avec le nom du champ contenant les noms des zones (dans fichier shapefile du dossier <a href="dmpipeline/ANNEX_Data/Territory/Areas">Areas</a>). KEY_STAT est facultatif, mais dans ce cas le champ doit être nommé ‘nom’.</p>
<p>Pour la chaine LOCALE, les tuiles Landsat et S2 à collecter sur GEE peuvent être pré-définies par l’utilisateur pour réduire le nombre de produits satellites haute résolution à traiter. Cela peut être utile pour des premiers tests, afin de gagner du temps. Si aucune tuile n’est donnée, la chaine collectera automatiquement les tuiles interceptant le territoire (TERRITORY) ou la zone de découpe fournie par l’utilisateur via le fichier Landmask_Grid_ROI (si LANDMASK_ROI=1).</p>
<p>A l’issue des traitements, contrôler si les dossiers de sortie de run (WRK_DIR/RUN_*) contiennent bien les produits attendus selon les préconisations décrites dans le fichier <a href="dmpipeline/DOC/PROCEDURE_QUALITE_INDICATEURS.xlsx">PROCEDURE_QUALITE_INDICATEURS</a>. Vérifier si les produits historiques sont également copiés vers le DATA_HISTO, à savoir : - indices composites (décades, mois) - indicateurs (décades, mois) - table(s) contenant les séries temporelles des statistiques spatiales pour chaque zone (chaine GLOBALE, si calcul demandé depuis fichier de config).</p>
<section id="préconisations-de-configuration-pour-lancement-historique-mode-auto" class="level4" data-number="6.2.1">
<h4 data-number="6.2.1" class="anchored" data-anchor-id="préconisations-de-configuration-pour-lancement-historique-mode-auto"><span class="header-section-number">6.2.1</span> Préconisations de configuration pour lancement historique (MODE = AUTO)</h4>
<p>Lancer les chaines en mode AUTO pour que celles-ci calculent automatiquement le début et la fin de la période du référentiel historique, correspondant respectivement à la date du premier produit trouvé sur GEE et la date de fin de la décade complète la plus récente (inutile de remplir PERIOD_START et PERIOD_END). Les chaines étant indépendantes, les référentiels historiques peuvent être différents d’une chaine à l’autre.</p>
<p>Mettre ASSET_EXPORT_* à 0 pour gagner du temps, ou alors s’assurer que suffisement d’espace est disponible sur GEE pour contenir l’ensemble des produits mono-dates. Pour la chaine LOCALE, les 250 Go d’espace GEE mis à disposition seront parfois insuffisants selon le territoire traité. Nous recommandons de ne pas paramétrer l’export sur GEE lors de l’exécution de la chaine LOCALE sur tout l’historique (2000 - ce jour).</p>
<p>A noter : en utilisation sous docker (“Service-Regulier”), le mode AUTO permettra également de relancer automatiquement les chaines lorsque de nouveaux produits seront disponibles sur GEE (ce qui n’est pas le cas en utilisation “Test”).</p>
</section>
<section id="calcul-des-indices-ou-indicateurs-uniquement-mode-indicesdrought" class="level4" data-number="6.2.2">
<h4 data-number="6.2.2" class="anchored" data-anchor-id="calcul-des-indices-ou-indicateurs-uniquement-mode-indicesdrought"><span class="header-section-number">6.2.2</span> Calcul des indices ou indicateurs uniquement (MODE = INDICES/DROUGHT)</h4>
<p>Il est possible de lancer qu’une partie des traitements de la chaine.</p>
<p>Le mode INDICE permet de calculer uniquement les indices composites en fixant manuellement la période de traitement. Peut s’avérer utile si besoin de recaculer les indices pour une période spécifique (produits erronés, pertes de données), puis relancer la chaine en mode AUTO par exemple.</p>
<p>Le mode DROUGHT permet de calculer uniquement les indicateurs. Cela implique de disposer au préalable d’un référentiel historique d’indices déjà calculés. Peut être utile pour mettre à jour les indicateurs sans recalcul des indices composites. L’utilisateur peut donner une période en entrée qui définira les mois de l’année à recalculer, les indicateurs étant calculés par rapport à des anomalies a minima mensuelles (VHI), voire décadaires (VHI, VAI). Par exemple, le paramétrage ‘PERIOD_START=2020-01-01’ et ‘PERIOD_END=2020-03-01’ entrainera un calcul des indicateurs pour tous les mois de Janvier et Février disponibles (PERIOD_END est exclusive). Ici seul le numéro du mois compte dans ce qui est donné en entrée de PERIOD_START et PERIOD_END. Si aucune période n’est donnée, tous les mois de l’année disponibles seront mis à jour.</p>
</section>
</section>
</section>
<section id="intégration-continue-ci" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="intégration-continue-ci"><span class="header-section-number">7</span> Intégration Continue (CI)</h2>
<section id="agent-azure-devops" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="agent-azure-devops"><span class="header-section-number">7.1</span> Agent Azure DevOps</h3>
<p>L’installation de l’agent Azure DevOps, assurant le bon déploiement de ce projet sur le serveur INSIGHT, a été décrit dans une documentation interne de l’Oeil <a href="https://dev.azure.com/Oeilnc/_git/Backup?path=/README.md&amp;_a=preview">Backup</a> afin d’assurer une centralisation de l’information des procedures d’exploitation de l’infrastructure générale de l’Observatoire.</p>
</section>
<section id="déclenchement" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="déclenchement"><span class="header-section-number">7.2</span> Déclenchement</h3>
<p>L’intégration continue (CI) ne se déclenche qu’à 2 conditions : - un commit vient d’être poussé sur la branche master - un tag vient d’être créé au format : v<em>.</em>.* (ex: v1.0.2) Si un commit est poussé sur une autre branche que master ou si un tag est créé qui n’est pas au format indiqué, aucun déploiement ne sera exécuté.</p>
<p>Lorsqu’un commit est poussé sur le branche master, c’est le serveur de QUALIF qui est mis à jour. Lorsqu’un tag est poussé (au bon format), c’est le serveur de PROD qui est mis à jour.</p>
</section>
<section id="déploiement-en-prod" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="déploiement-en-prod"><span class="header-section-number">7.3</span> Déploiement en PROD</h3>
<p>Depuis Azure Devops, il faut créer un nouveau pool d’agent et y déployer un nouvel agent Azure dessus. Pour ce faire, il suffit de suivre la documentation du projet Backup (partie <code>Installation d'un agent Azure sur un serveur extérieur</code>). Il faudra ensuite modifier le fichier <a href="azure-pipelines.yml">azure-pipelines.yml</a> de ce projet pour mettre à jour le nom du pool Azure dans le job qui déploie sur le serveur de PROD.</p>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Réutilisation</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/SA/deed.fr">CC BY SA</a></div></div></section><section class="quarto-appendix-contents" id="quarto-copyright"><h2 class="anchored quarto-appendix-heading">Droits d'auteur</h2><div class="quarto-appendix-contents"><div>OEIL - Observatoire de l'Environnement en Nouvelle-Calédonie, tous droits réservés</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copié");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copié");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>